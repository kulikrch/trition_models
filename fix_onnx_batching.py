"""
–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ ONNX –º–æ–¥–µ–ª–∏ –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ dynamic batching –≤ Triton
"""
import torch
import onnx
from onnx import version_converter
import os
from working_demo import SimpleCNN

def recreate_onnx_with_dynamic_batching():
    """–ü–µ—Ä–µ—Å–æ–∑–¥–∞–µ—Ç ONNX –º–æ–¥–µ–ª—å —Å dynamic batching"""
    print("üîÑ –ü–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ ONNX –º–æ–¥–µ–ª–∏ —Å dynamic batching...")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º PyTorch –º–æ–¥–µ–ª—å
    model = SimpleCNN(num_classes=10)
    checkpoint = torch.load("models/working_model.pth", map_location='cpu')
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    
    # –°–æ–∑–¥–∞–µ–º dummy input
    dummy_input = torch.randn(1, 3, 32, 32)
    
    # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Å dynamic axes –¥–ª—è batch dimension
    onnx_path = "triton/model_repository/cifar10_onnx/1/model.onnx"
    
    torch.onnx.export(
        model,
        dummy_input,
        onnx_path,
        export_params=True,
        opset_version=11,
        do_constant_folding=True,
        input_names=['input'],
        output_names=['output'],
        dynamic_axes={
            'input': {0: 'batch_size'},    # –î–µ–ª–∞–µ–º batch —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π
            'output': {0: 'batch_size'}    # –î–µ–ª–∞–µ–º batch —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π
        }
    )
    
    print(f"‚úÖ ONNX –º–æ–¥–µ–ª—å –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∞: {onnx_path}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–æ–¥–µ–ª—å
    onnx_model = onnx.load(onnx_path)
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Ö–æ–¥—ã
    for inp in onnx_model.graph.input:
        print(f"   Input: {inp.name}")
        for i, dim in enumerate(inp.type.tensor_type.shape.dim):
            if dim.dim_param:
                print(f"      Dim {i}: {dim.dim_param} (dynamic)")
            else:
                print(f"      Dim {i}: {dim.dim_value} (fixed)")
    
    return True

def fix_onnx_optimized():
    """–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é ONNX –º–æ–¥–µ–ª—å"""
    print("\nüîÑ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π ONNX –º–æ–¥–µ–ª–∏...")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º PyTorch –º–æ–¥–µ–ª—å
    model = SimpleCNN(num_classes=10)
    checkpoint = torch.load("models/working_model.pth", map_location='cpu')
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    
    # –°–æ–∑–¥–∞–µ–º dummy input
    dummy_input = torch.randn(1, 3, 32, 32)
    
    # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é
    onnx_opt_path = "triton/model_repository/cifar10_onnx_optimized/1/model.onnx"
    
    torch.onnx.export(
        model,
        dummy_input,
        onnx_opt_path,
        export_params=True,
        opset_version=11,
        do_constant_folding=True,  # –ë–æ–ª—å—à–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π
        input_names=['input'],
        output_names=['output'],
        dynamic_axes={
            'input': {0: 'batch_size'},
            'output': {0: 'batch_size'}
        }
    )
    
    print(f"‚úÖ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è ONNX –º–æ–¥–µ–ª—å –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∞: {onnx_opt_path}")
    return True

def fix_onnx_optimized_config():
    """–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫—É—é –æ—à–∏–±–∫—É –≤ –∫–æ–Ω—Ñ–∏–≥–µ"""
    print("\nüîß –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ cifar10_onnx_optimized...")
    
    config_content = '''name: "cifar10_onnx_optimized"
platform: "onnxruntime_onnx"
max_batch_size: 16
input [
  {
    name: "input"
    data_type: TYPE_FP32
    dims: [ 3, 32, 32 ]
  }
]
output [
  {
    name: "output"
    data_type: TYPE_FP32
    dims: [ 10 ]
  }
]

optimization {
  execution_accelerators {
    cpu_execution_accelerator : [ {
      name : "openvino"
    }]
  }
}

instance_group [
  {
    count: 2
    kind: KIND_CPU
  }
]

dynamic_batching {
  max_queue_delay_microseconds: 50
  preferred_batch_size: [ 4, 8 ]
}

version_policy: { all { }}
'''
    
    config_path = "triton/model_repository/cifar10_onnx_optimized/config.pbtxt"
    
    with open(config_path, 'w') as f:
        f.write(config_content)
    
    print(f"‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∞: {config_path}")
    return True

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üîß –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï ONNX –ú–û–î–ï–õ–ï–ô –î–õ–Ø TRITON")
    print("=" * 50)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
    os.makedirs("triton/model_repository/cifar10_onnx/1", exist_ok=True)
    os.makedirs("triton/model_repository/cifar10_onnx_optimized/1", exist_ok=True)
    
    success = True
    
    # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –±–∞–∑–æ–≤—É—é ONNX –º–æ–¥–µ–ª—å
    if not recreate_onnx_with_dynamic_batching():
        success = False
    
    # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é ONNX –º–æ–¥–µ–ª—å
    if not fix_onnx_optimized():
        success = False
    
    # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    if not fix_onnx_optimized_config():
        success = False
    
    if success:
        print(f"\nüéâ –í–°–ï ONNX –ú–û–î–ï–õ–ò –ò–°–ü–†–ê–í–õ–ï–ù–´!")
        print("=" * 40)
        print("‚úÖ cifar10_onnx - dynamic batching –≤–∫–ª—é—á–µ–Ω")
        print("‚úÖ cifar10_onnx_optimized - dynamic batching + OpenVINO")
        print("‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω—ã")
        
        print(f"\nüöÄ –°–ª–µ–¥—É—é—â–∏–π —à–∞–≥:")
        print("docker-compose -f docker-compose-triton.yml restart triton")
        
    return success

if __name__ == "__main__":
    main()