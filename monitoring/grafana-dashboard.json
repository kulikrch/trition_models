{
  "dashboard": {
    "id": null,
    "title": "ML Model Inference Dashboard",
    "tags": ["ml", "inference", "triton"],
    "style": "dark",
    "timezone": "browser",
    "panels": [
      {
        "id": 1,
        "title": "Triton Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(nv_inference_request_success[5m])",
            "legendFormat": "{{model}} - {{version}}"
          }
        ],
        "yAxes": [
          {
            "label": "Requests/sec"
          }
        ],
        "gridPos": {
          "h": 8,
          "w": 12,
          "x": 0,
          "y": 0
        }
      },
      {
        "id": 2,
        "title": "Triton Request Latency",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(nv_inference_request_duration_us_bucket[5m]))",
            "legendFormat": "95th percentile"
          },
          {
            "expr": "histogram_quantile(0.50, rate(nv_inference_request_duration_us_bucket[5m]))",
            "legendFormat": "50th percentile"
          }
        ],
        "yAxes": [
          {
            "label": "Latency (Î¼s)"
          }
        ],
        "gridPos": {
          "h": 8,
          "w": 12,
          "x": 12,
          "y": 0
        }
      },
      {
        "id": 3,
        "title": "GPU Utilization",
        "type": "graph",
        "targets": [
          {
            "expr": "nv_gpu_utilization",
            "legendFormat": "GPU {{gpu}}"
          }
        ],
        "yAxes": [
          {
            "label": "Utilization (%)",
            "max": 100
          }
        ],
        "gridPos": {
          "h": 8,
          "w": 12,
          "x": 0,
          "y": 8
        }
      },
      {
        "id": 4,
        "title": "GPU Memory Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "nv_gpu_memory_used_bytes",
            "legendFormat": "Used - GPU {{gpu}}"
          },
          {
            "expr": "nv_gpu_memory_total_bytes",
            "legendFormat": "Total - GPU {{gpu}}"
          }
        ],
        "yAxes": [
          {
            "label": "Memory (bytes)"
          }
        ],
        "gridPos": {
          "h": 8,
          "w": 12,
          "x": 12,
          "y": 8
        }
      },
      {
        "id": 5,
        "title": "Preprocessing Service Metrics",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(preprocess_requests_total[5m])",
            "legendFormat": "Request Rate"
          },
          {
            "expr": "rate(preprocess_errors_total[5m])",
            "legendFormat": "Error Rate"
          }
        ],
        "yAxes": [
          {
            "label": "Requests/sec"
          }
        ],
        "gridPos": {
          "h": 8,
          "w": 12,
          "x": 0,
          "y": 16
        }
      },
      {
        "id": 6,
        "title": "Preprocessing Duration",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(preprocess_request_duration_seconds_bucket[5m]))",
            "legendFormat": "95th percentile"
          },
          {
            "expr": "histogram_quantile(0.50, rate(preprocess_request_duration_seconds_bucket[5m]))",
            "legendFormat": "50th percentile"
          }
        ],
        "yAxes": [
          {
            "label": "Duration (seconds)"
          }
        ],
        "gridPos": {
          "h": 8,
          "w": 12,
          "x": 12,
          "y": 16
        }
      }
    ],
    "time": {
      "from": "now-1h",
      "to": "now"
    },
    "refresh": "5s"
  }
}