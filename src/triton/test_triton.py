"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –≤ Triton Inference Server
"""
import tritonclient.grpc as grpcclient
import tritonclient.http as httpclient
import numpy as np
import time
import sys
import os

class TritonTester:
    def __init__(self, triton_url="triton:8001", use_grpc=True):
        self.triton_url = triton_url
        self.use_grpc = use_grpc
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞
        if use_grpc:
            self.client = grpcclient.InferenceServerClient(url=triton_url)
        else:
            http_url = triton_url.replace(':8001', ':8002')
            self.client = httpclient.InferenceServerClient(url=http_url)
        
        # CIFAR-10 –∫–ª–∞—Å—Å—ã
        self.class_names = [
            'airplane', 'automobile', 'bird', 'cat', 'deer',
            'dog', 'frog', 'horse', 'ship', 'truck'
        ]
    
    def wait_for_triton(self, max_retries=30):
        """–ñ–¥–µ—Ç –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ Triton —Å–µ—Ä–≤–µ—Ä–∞"""
        print("‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ Triton —Å–µ—Ä–≤–µ—Ä–∞...")
        
        for i in range(max_retries):
            try:
                if self.client.is_server_live():
                    if self.client.is_server_ready():
                        print("‚úÖ Triton —Å–µ—Ä–≤–µ—Ä –≥–æ—Ç–æ–≤!")
                        return True
                    else:
                        print(f"   –°–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω, –Ω–æ –Ω–µ –≥–æ—Ç–æ–≤... ({i+1}/{max_retries})")
                else:
                    print(f"   –°–µ—Ä–≤–µ—Ä –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç... ({i+1}/{max_retries})")
            except Exception as e:
                print(f"   –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e} ({i+1}/{max_retries})")
            
            time.sleep(5)
        
        print("‚ùå Triton —Å–µ—Ä–≤–µ—Ä –Ω–µ –≥–æ—Ç–æ–≤")
        return False
    
    def list_models(self):
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        try:
            models = self.client.get_model_repository_index()
            print("üìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:")
            
            available_models = []
            for model in models:
                name = model['name'] if isinstance(model, dict) else model.name
                state = model['state'] if isinstance(model, dict) else model.state
                print(f"   ‚Ä¢ {name}: {state}")
                
                if state == 'READY':
                    available_models.append(name)
            
            return available_models
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π: {e}")
            return []
    
    def get_model_metadata(self, model_name):
        """–ü–æ–ª—É—á–∞–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏"""
        try:
            metadata = self.client.get_model_metadata(model_name)
            
            print(f"üìä –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ {model_name}:")
            if hasattr(metadata, 'platform'):
                print(f"   Platform: {metadata.platform}")
            if hasattr(metadata, 'inputs'):
                for inp in metadata.inputs:
                    print(f"   Input: {inp.name}, shape: {inp.shape}, dtype: {inp.datatype}")
            if hasattr(metadata, 'outputs'):
                for out in metadata.outputs:
                    print(f"   Output: {out.name}, shape: {out.shape}, dtype: {out.datatype}")
            
            return metadata
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {e}")
            return None
    
    def create_test_data(self, batch_size=1):
        """–°–æ–∑–¥–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ"""
        # –°–æ–∑–¥–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ CIFAR-10
        data = np.random.randn(batch_size, 3, 32, 32).astype(np.float32)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞–∫ –≤ –æ–±—É—á–µ–Ω–∏–∏
        mean = np.array([0.4914, 0.4822, 0.4465]).reshape(1, 3, 1, 1)
        std = np.array([0.2023, 0.1994, 0.2010]).reshape(1, 3, 1, 1)
        data = (data - mean) / std
        
        return data
    
    def test_model_inference(self, model_name, num_tests=10):
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∏–Ω—Ñ–µ—Ä–µ–Ω—Å –º–æ–¥–µ–ª–∏"""
        print(f"üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏: {model_name}")
        
        # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        metadata = self.get_model_metadata(model_name)
        if not metadata:
            return None
        
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–º–µ–Ω–∞ –≤—Ö–æ–¥–æ–≤ –∏ –≤—ã—Ö–æ–¥–æ–≤
            if hasattr(metadata, 'inputs') and len(metadata.inputs) > 0:
                input_name = metadata.inputs[0].name
                input_shape = metadata.inputs[0].shape
            else:
                input_name = 'input'
                input_shape = [3, 32, 32]
            
            if hasattr(metadata, 'outputs') and len(metadata.outputs) > 0:
                output_name = metadata.outputs[0].name
            else:
                output_name = 'output'
            
            print(f"   Input: {input_name}, Output: {output_name}")
            
            # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            test_data = self.create_test_data(batch_size=1)
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å
            if self.use_grpc:
                inputs = [grpcclient.InferInput(input_name, test_data.shape, "FP32")]
                inputs[0].set_data_from_numpy(test_data)
                outputs = [grpcclient.InferRequestedOutput(output_name)]
            else:
                inputs = [httpclient.InferInput(input_name, test_data.shape, "FP32")]
                inputs[0].set_data_from_numpy(test_data)
                outputs = [httpclient.InferRequestedOutput(output_name)]
            
            # –ü—Ä–æ–≥—Ä–µ–≤
            for _ in range(3):
                try:
                    response = self.client.infer(model_name, inputs, outputs=outputs)
                except:
                    pass
            
            # –ò–∑–º–µ—Ä–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            times = []
            results = []
            
            for i in range(num_tests):
                start_time = time.time()
                
                try:
                    response = self.client.infer(model_name, inputs, outputs=outputs)
                    end_time = time.time()
                    
                    # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    if self.use_grpc:
                        output_data = response.as_numpy(output_name)
                    else:
                        output_data = response.as_numpy(output_name)
                    
                    times.append(end_time - start_time)
                    
                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                    predicted_class = np.argmax(output_data[0])
                    confidence = np.max(np.softmax(output_data[0]))
                    results.append((predicted_class, confidence))
                    
                except Exception as e:
                    print(f"   ‚ùå –û—à–∏–±–∫–∞ –≤ —Ç–µ—Å—Ç–µ {i+1}: {e}")
                    continue
            
            if times:
                avg_time = np.mean(times) * 1000  # ms
                std_time = np.std(times) * 1000
                min_time = np.min(times) * 1000
                max_time = np.max(times) * 1000
                throughput = 1000 / avg_time  # fps
                
                # –ü–æ—Å–ª–µ–¥–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
                if results:
                    last_class, last_conf = results[-1]
                    class_name = self.class_names[last_class]
                
                print(f"   üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã ({len(times)} —É—Å–ø–µ—à–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤):")
                print(f"      –í—Ä–µ–º—è: {avg_time:.2f} ¬± {std_time:.2f} ms")
                print(f"      –î–∏–∞–ø–∞–∑–æ–Ω: {min_time:.2f} - {max_time:.2f} ms")
                print(f"      Throughput: {throughput:.1f} fps")
                if results:
                    print(f"      –ü—Ä–∏–º–µ—Ä: {class_name} ({last_conf:.3f})")
                
                return {
                    'model_name': model_name,
                    'successful_tests': len(times),
                    'avg_time_ms': avg_time,
                    'std_time_ms': std_time,
                    'min_time_ms': min_time,
                    'max_time_ms': max_time,
                    'throughput_fps': throughput,
                    'sample_prediction': class_name if results else None,
                    'sample_confidence': last_conf if results else None
                }
            else:
                print(f"   ‚ùå –í—Å–µ —Ç–µ—Å—Ç—ã –Ω–µ—É–¥–∞—á–Ω—ã")
                return None
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ {model_name}: {e}")
            return None
    
    def run_comprehensive_test(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π"""
        print("üöÄ –ö–û–ú–ü–õ–ï–ö–°–ù–û–ï –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï TRITON INFERENCE SERVER")
        print("=" * 70)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å —Å–µ—Ä–≤–µ—Ä–∞
        if not self.wait_for_triton():
            return False
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
        available_models = self.list_models()
        if not available_models:
            print("‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π")
            return False
        
        print(f"\nüéØ –ù–∞–π–¥–µ–Ω–æ {len(available_models)} –≥–æ—Ç–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é –º–æ–¥–µ–ª—å
        results = []
        
        for i, model_name in enumerate(available_models, 1):
            print(f"\n{i}Ô∏è‚É£ {'='*50}")
            print(f"{i}Ô∏è‚É£ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï: {model_name.upper()}")
            print(f"{i}Ô∏è‚É£ {'='*50}")
            
            result = self.test_model_inference(model_name, num_tests=20)
            if result:
                results.append(result)
        
        # –ò—Ç–æ–≥–æ–≤–∞—è —Å–≤–æ–¥–∫–∞
        if results:
            self.print_summary_table(results)
        
        return len(results) > 0
    
    def print_summary_table(self, results):
        """–ü–µ—á–∞—Ç–∞–µ—Ç –∏—Ç–æ–≥–æ–≤—É—é —Ç–∞–±–ª–∏—Ü—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        print("\nüéâ " + "="*80 + " üéâ")
        print("üéâ" + " "*25 + "–ò–¢–û–ì–û–í–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´ TRITON" + " "*25 + "üéâ")
        print("üéâ " + "="*80 + " üéâ")
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Ç–∞–±–ª–∏—Ü—ã
        print(f"{'–ú–æ–¥–µ–ª—å':<25} {'–í—Ä–µ–º—è (ms)':<12} {'Throughput':<12} {'–¢–µ—Å—Ç–æ–≤':<8}")
        print("-" * 70)
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
        for result in results:
            name = result['model_name']
            time_ms = f"{result['avg_time_ms']:.2f}"
            throughput = f"{result['throughput_fps']:.1f} fps"
            tests = result['successful_tests']
            
            print(f"{name:<25} {time_ms:<12} {throughput:<12} {tests:<8}")
        
        # –õ—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        print(f"\nüèÜ –õ–£–ß–®–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
        print("-" * 30)
        
        fastest = min(results, key=lambda x: x['avg_time_ms'])
        highest_throughput = max(results, key=lambda x: x['throughput_fps'])
        
        print(f"üöÄ –°–∞–º–∞—è –±—ã—Å—Ç—Ä–∞—è: {fastest['model_name']} ({fastest['avg_time_ms']:.2f} ms)")
        print(f"üöÑ –ù–∞–∏–≤—ã—Å—à–∏–π throughput: {highest_throughput['model_name']} ({highest_throughput['throughput_fps']:.1f} fps)")

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    triton_url = os.getenv('TRITON_URL', 'triton:8001')
    
    print(f"üîó –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Triton: {triton_url}")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º gRPC
    print(f"\nüì° –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï gRPC –ò–ù–¢–ï–†–§–ï–ô–°–ê")
    print("-" * 40)
    
    try:
        grpc_tester = TritonTester(triton_url, use_grpc=True)
        grpc_success = grpc_tester.run_comprehensive_test()
    except Exception as e:
        print(f"‚ùå gRPC —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ—É–¥–∞—á–Ω–æ: {e}")
        grpc_success = False
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º HTTP (–µ—Å–ª–∏ gRPC –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç)
    if not grpc_success:
        print(f"\nüåê –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï HTTP –ò–ù–¢–ï–†–§–ï–ô–°–ê")
        print("-" * 40)
        
        try:
            http_url = triton_url.replace(':8001', ':8002')
            http_tester = TritonTester(http_url, use_grpc=False)
            http_success = http_tester.run_comprehensive_test()
        except Exception as e:
            print(f"‚ùå HTTP —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ—É–¥–∞—á–Ω–æ: {e}")
            http_success = False
    else:
        http_success = True
    
    # –ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    if grpc_success or http_success:
        print(f"\n‚úÖ TRITON INFERENCE SERVER –ü–†–û–¢–ï–°–¢–ò–†–û–í–ê–ù –£–°–ü–ï–®–ù–û!")
        return True
    else:
        print(f"\n‚ùå –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï TRITON –ù–ï–£–î–ê–ß–ù–û")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)