# –û–¢–ß–ï–¢ –ü–û –î–û–ú–ê–®–ù–ï–ú–£ –ó–ê–î–ê–ù–ò–Æ: –≠–ö–°–ü–õ–£–ê–¢–ê–¶–ò–Ø ML –ú–û–î–ï–õ–ï–ô

## –û–ë–©–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø
- **–í—ã–ø–æ–ª–Ω–∏–ª**: [–≤–∞—à–µ –∏–º—è]
- **–î–∞—Ç–∞**: [–¥–∞—Ç–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è]
- **–ü–ª–∞—Ç—Ñ–æ—Ä–º–∞**: CPU (–±–µ–∑ GPU)
- **–û–°**: Windows 10/11

---

## 1. –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò ‚úÖ

### –ß—Ç–æ —Å–¥–µ–ª–∞–Ω–æ:
- –û–±—É—á–µ–Ω–∞ CNN –º–æ–¥–µ–ª—å –Ω–∞ –±–∞–∑–µ **PyTorch**
- –ó–∞–¥–∞—á–∞: –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π CIFAR-10 (10 –∫–ª–∞—Å—Å–æ–≤)
- –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: Custom CNN —Å 3 —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–º–∏ —Å–ª–æ—è–º–∏ + 2 –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã—Ö

### –§–∞–π–ª—ã:
- `src/train/model.py` - –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏
- `src/train/train.py` - —Å–∫—Ä–∏–ø—Ç –æ–±—É—á–µ–Ω–∏—è
- `working_demo.py` - —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è CPU
- `models/working_model.pth` - –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å

### –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è:
```
–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö: 3-5 (–¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏)
–§–∏–Ω–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: ~65-70%
–í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –Ω–∞ CPU: ~5-10 –º–∏–Ω—É—Ç
–†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏: 1.2 MB
```

### –ö–∞–∫ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å:
```bash
python working_demo.py
# –ò–ª–∏
python simple_train.py 5
```

---

## 2. –ö–û–ù–í–ï–†–¢–ê–¶–ò–Ø –í ONNX ‚úÖ

### –ß—Ç–æ —Å–¥–µ–ª–∞–Ω–æ:
- –≠–∫—Å–ø–æ—Ä—Ç PyTorch –º–æ–¥–µ–ª–∏ –≤ —Ñ–æ—Ä–º–∞—Ç ONNX
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω torch.onnx.export —Å opset_version=11
- –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏

### –§–∞–π–ª—ã:
- `src/convert/to_onnx.py` - —Å–∫—Ä–∏–ø—Ç –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
- `models/working_model.onnx` - ONNX –º–æ–¥–µ–ª—å

### –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏:
```
–†–∞–∑–º–µ—Ä ONNX –º–æ–¥–µ–ª–∏: 2.08 MB (–∏–¥–µ–Ω—Ç–∏—á–µ–Ω –∏—Å—Ö–æ–¥–Ω–æ–º—É)
–¢–æ—á–Ω–æ—Å—Ç—å: –±–µ–∑ –ø–æ—Ç–µ—Ä—å
–í—Ä–µ–º—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏: ~30 —Å–µ–∫—É–Ω–¥
–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å: –ø—Ä–æ–≤–µ—Ä–µ–Ω–∞ —Å ONNX Runtime
–£–°–ö–û–†–ï–ù–ò–ï: 15.4x (1.91 ms ‚Üí 0.12 ms)
THROUGHPUT: 8,057 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ —Å–µ–∫—É–Ω–¥—É!
```

### –ö–∞–∫ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å:
```bash
python src/convert/to_onnx.py
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–ª–∏—á–∏–µ: models/working_model.onnx
```

---

## 3. –ö–û–ù–í–ï–†–¢–ê–¶–ò–Ø –í TRT ‚ùå (–ü–†–û–ü–£–©–ï–ù–û)

### –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ:
- TensorRT —Ç—Ä–µ–±—É–µ—Ç NVIDIA GPU
- –ü—Ä–æ–µ–∫—Ç –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω –¥–ª—è CPU
- –ù–∞ CPU –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è ONNX Runtime –∫–∞–∫ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞

---

## 4. –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –ú–û–î–ï–õ–ò –°–†–ï–î–°–¢–í–ê–ú–ò TORCH ‚úÖ

### –ß—Ç–æ —Å–¥–µ–ª–∞–Ω–æ:
- **Quantization**: –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è INT8
- **Pruning**: –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä—É–Ω–∏–Ω–≥ (30% –≤–µ—Å–æ–≤)
- **Combined**: –ö–æ–º–±–∏–Ω–∞—Ü–∏—è –æ–±–µ–∏—Ö —Ç–µ—Ö–Ω–∏–∫

### –§–∞–π–ª—ã:
- `src/optimize/pytorch_optimize.py` - —Å–∫—Ä–∏–ø—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
- `models/cifar10_model_quantized.pth` - –∫–≤–∞–Ω—Ç–∏–∑–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
- `models/cifar10_model_pruned.pth` - –º–æ–¥–µ–ª—å —Å –ø—Ä—É–Ω–∏–Ω–≥–æ–º
- `models/cifar10_model_combined.pth` - –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è

### –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ (—Ä–µ–∞–ª—å–Ω—ã–µ –∏–∑–º–µ—Ä–µ–Ω–∏—è –Ω–∞ 100 –∏—Ç–µ—Ä–∞—Ü–∏—è—Ö):

| –ú–æ–¥–µ–ª—å | –†–∞–∑–º–µ—Ä | –í—Ä–µ–º—è (ms) | Throughput | –£—Å–∫–æ—Ä–µ–Ω–∏–µ | –°–∂–∞—Ç–∏–µ |
|--------|--------|------------|------------|-----------|--------|
| **PyTorch Original** | 2.08 MB | 1.91 ms | 523 fps | 1.0x | 1.0x |
| **ONNX** | 2.08 MB | **0.12 ms** | **8,058 fps** | **15.4x** | 1.0x |
| **PyTorch Quantized** | 0.58 MB | 1.10 ms | 912 fps | **1.7x** | **3.6x** |
| **PyTorch Pruned** | 2.08 MB | 0.61 ms | 1,640 fps | **3.1x** | 1.0x |
| **PyTorch Combined** | 0.58 MB | 0.94 ms | 1,065 fps | **2.0x** | **3.6x** |

### –ö–∞–∫ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å:
```bash
python src/optimize/pytorch_optimize.py
```

---

## 5. –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø ONNX ‚úÖ

### –ß—Ç–æ —Å–¥–µ–ª–∞–Ω–æ:
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω ONNX Runtime –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
- –ü—Ä–∏–º–µ–Ω–µ–Ω—ã CPU-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
- –ù–∞—Å—Ç—Ä–æ–µ–Ω–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

### –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:
- **Speedup**: 2x –±—ã—Å—Ç—Ä–µ–µ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π PyTorch –º–æ–¥–µ–ª–∏
- **–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å**: –†–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ –ª—é–±–æ–º CPU
- **–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å**: –ò–¥–µ–Ω—Ç–∏—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

---

## 6. –ú–ò–ö–†–û–°–ï–†–í–ò–° –ü–†–ï–î–û–ë–†–ê–ë–û–¢–ö–ò ‚úÖ

### –ß—Ç–æ —Å–¥–µ–ª–∞–Ω–æ:
- –†–∞–∑—Ä–∞–±–æ—Ç–∞–Ω –Ω–∞ **FastAPI**
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
- –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è CIFAR-10
- Prometheus –º–µ—Ç—Ä–∏–∫–∏
- Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä

### –§–∞–π–ª—ã:
- `src/preprocess_service/main.py` - –æ—Å–Ω–æ–≤–Ω–æ–π —Å–µ—Ä–≤–∏—Å
- `web_app.py` - –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
- `docker/Dockerfile.webapp` - Docker –æ–±—Ä–∞–∑

### API Endpoints:
```
POST /predict - –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
GET /health - –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è
GET /stats - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
GET /metrics - Prometheus –º–µ—Ç—Ä–∏–∫–∏
```

### –ö–∞–∫ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å:
```bash
python web_app.py
# –û—Ç–∫—Ä—ã—Ç—å: http://localhost:8000
```

---

## 7. –†–ê–ó–í–ï–†–¢–´–í–ê–ù–ò–ï –í TRITON INFERENCE SERVER ‚úÖ (–í–´–ü–û–õ–ù–ï–ù–û)

### –°—Ç–∞—Ç—É—Å: ‚úÖ Triton Inference Server —É—Å–ø–µ—à–Ω–æ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç –∏ –∑–∞–ø—É—â–µ–Ω

### –ß—Ç–æ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç–æ –∏ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ:

#### ‚úÖ **–£—Å–ø–µ—à–Ω–æ —Ä–∞–±–æ—Ç–∞—é—â–∏–µ –º–æ–¥–µ–ª–∏:**
1. **cifar10_pytorch** - –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è PyTorch –º–æ–¥–µ–ª—å
   - –ü–ª–∞—Ç—Ñ–æ—Ä–º–∞: pytorch_libtorch
   - –°—Ç–∞—Ç—É—Å: **READY**
   - Backend: CPU
   - Dynamic batching: –≤–∫–ª—é—á–µ–Ω

2. **cifar10_onnx_optimized** - –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è ONNX –º–æ–¥–µ–ª—å
   - –ü–ª–∞—Ç—Ñ–æ—Ä–º–∞: onnxruntime_onnx 
   - –°—Ç–∞—Ç—É—Å: **READY** 
   - Backend: CPU + **OpenVINO** —É—Å–∫–æ—Ä–µ–Ω–∏–µ!
   - Instances: 2 (–¥–ª—è –ø–æ–≤—ã—à–µ–Ω–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏)

#### ‚ö†Ô∏è **–ß–∞—Å—Ç–∏—á–Ω–æ —Ä–∞–±–æ—Ç–∞—é—â–∏–µ –º–æ–¥–µ–ª–∏:**
3. **cifar10_onnx** - –ë–∞–∑–æ–≤–∞—è ONNX –º–æ–¥–µ–ª—å
   - –°—Ç–∞—Ç—É—Å: UNAVAILABLE (–ø—Ä–æ–±–ª–µ–º–∞ —Å batching shape)
   - –û—à–∏–±–∫–∞: –¢—Ä–µ–±—É–µ—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

4. **cifar10_optimized** - –ö–≤–∞–Ω—Ç–∏–∑–æ–≤–∞–Ω–Ω–∞—è PyTorch –º–æ–¥–µ–ª—å  
   - –°—Ç–∞—Ç—É—Å: UNAVAILABLE (–ø—Ä–æ–±–ª–µ–º–∞ —Å TorchScript serialization)
   - –û—à–∏–±–∫–∞: –ö–≤–∞–Ω—Ç–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ —Ç—Ä–µ–±—É—é—Ç –æ—Å–æ–±—ã–π —Ñ–æ—Ä–º–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è

### –î–µ—Ç–∞–ª–∏ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è:
```
Triton Server Version: 2.39.0
Docker Image: nvcr.io/nvidia/tritonserver:23.10-py3
–ü–æ—Ä—Ç—ã: 8001 (gRPC), 8002 (HTTP), 8003 (Metrics)
Model Repository: ./triton/model_repository/
Backend: CPU-only (OpenVINO –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è ONNX)
```

### –§–∞–π–ª—ã –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:
- `prepare_triton_simple.py` - –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Å–µ—Ö 4 –º–æ–¥–µ–ª–µ–π
- `triton/model_repository/` - —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è –º–æ–¥–µ–ª–µ–π
- `docker-compose-triton.yml` - –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–ø—É—Å–∫–∞
- `test_triton_simple.py` - —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ HTTP API

### –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ –ª–æ–≥–æ–≤ Triton:
```
‚úÖ cifar10_pytorch: READY - TorchScript –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞
‚úÖ cifar10_onnx_optimized: READY - OpenVINO —É—Å–∫–æ—Ä–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–æ
‚ùå cifar10_onnx: –¢—Ä–µ–±—É–µ—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è batching config
‚ùå cifar10_optimized: –ü—Ä–æ–±–ª–µ–º–∞ —Å –∫–≤–∞–Ω—Ç–∏–∑–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é
```

### –ß—Ç–æ –º–æ–∂–Ω–æ —É–≤–∏–¥–µ—Ç—å –≤ Triton:
- **Server Status**: http://localhost:8002/v2/health/ready
- **Model Repository**: http://localhost:8002/v2/models  
- **Inference API**: http://localhost:8002/v2/models/{model_name}/infer
- **Metrics**: http://localhost:8002/metrics

### –î–æ—Å—Ç–∏–≥–Ω—É—Ç—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:
‚úÖ **2 –º–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã –≤ Triton**  
‚úÖ **OpenVINO –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç** –¥–ª—è ONNX –º–æ–¥–µ–ª–∏  
‚úÖ **Dynamic batching –Ω–∞—Å—Ç—Ä–æ–µ–Ω** –¥–ª—è –æ–±–µ–∏—Ö –º–æ–¥–µ–ª–µ–π  
‚úÖ **CPU-–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π backend** —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∏—Ä—É–µ—Ç  
‚úÖ **HTTP API –≥–æ—Ç–æ–≤** –¥–ª—è production –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞  

### –í—ã–≤–æ–¥—ã:
Triton Inference Server —É—Å–ø–µ—à–Ω–æ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∫–∞–∫ PyTorch, —Ç–∞–∫ –∏ ONNX –º–æ–¥–µ–ª–µ–π. –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –¥–ª—è high-performance –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –±–∞—Ç—á–∏–Ω–≥–æ–º –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º. OpenVINO —É—Å–∫–æ—Ä–µ–Ω–∏–µ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –Ω–∞ Intel CPU.

---

## 8. –ú–û–ù–ò–¢–û–†–ò–ù–ì (PROMETHEUS + GRAFANA) ‚úÖ

### –ß—Ç–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ:
- **Prometheus** –¥–ª—è —Å–±–æ—Ä–∞ –º–µ—Ç—Ä–∏–∫
- **Grafana** –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
- **Node Exporter** –¥–ª—è —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
- **cAdvisor** –¥–ª—è –º–µ—Ç—Ä–∏–∫ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤

### –§–∞–π–ª—ã:
- `monitoring/prometheus-extended.yml`
- `monitoring/grafana-dashboard-extended.json`
- `monitoring/grafana-datasources.yml`

### –ú–µ—Ç—Ä–∏–∫–∏ ML –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è:
```
ml_predictions_total - –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
ml_inference_duration_seconds - –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
ml_predictions_by_class - —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–ª–∞—Å—Å–∞–º
http_request_duration_seconds - –≤—Ä–µ–º—è HTTP –∑–∞–ø—Ä–æ—Å–æ–≤
```

### –ß—Ç–æ –º–æ–∂–Ω–æ —É–≤–∏–¥–µ—Ç—å –≤ Grafana:
**URL**: http://localhost:3000 (admin/admin)

#### Dashboard "ML Web Application":
1. **Prediction Rate** - –≥—Ä–∞—Ñ–∏–∫ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –≤ —Å–µ–∫—É–Ω–¥—É
2. **Inference Time** - 95th percentile –≤—Ä–µ–º–µ–Ω–∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
3. **CPU Usage** - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ —Å–∏—Å—Ç–µ–º—ã
4. **Memory Usage** - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
5. **Predictions by Class** - –∫—Ä—É–≥–æ–≤–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞ –ø–æ –∫–ª–∞—Å—Å–∞–º
6. **HTTP Response Times** - –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ API

#### –°–∏—Å—Ç–µ–º–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏:
- CPU utilization –ø–æ —è–¥—Ä–∞–º
- Memory usage (used/available)
- Disk I/O
- Network traffic

---

## 9. DOCKER-COMPOSE –û–†–ö–ï–°–¢–†–ê–¶–ò–Ø ‚úÖ

### –ß—Ç–æ —Å–æ–∑–¥–∞–Ω–æ:
- `docker-compose-extended.yml` - –ø–æ–ª–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ health checks
- –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ volumes –∏ networks
- –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –º–µ–∂–¥—É —Å–µ—Ä–≤–∏—Å–∞–º–∏

### –°–µ—Ä–≤–∏—Å—ã –≤ —Å–æ—Å—Ç–∞–≤–µ:
1. **ml-webapp** - ML –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ (–ø–æ—Ä—Ç 8000)
2. **prometheus** - —Å–±–æ—Ä –º–µ—Ç—Ä–∏–∫ (–ø–æ—Ä—Ç 9090)
3. **grafana** - –¥–∞—à–±–æ—Ä–¥—ã (–ø–æ—Ä—Ç 3000)
4. **node-exporter** - —Å–∏—Å—Ç–µ–º–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (–ø–æ—Ä—Ç 9100)
5. **cadvisor** - –º–µ—Ç—Ä–∏–∫–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ (–ø–æ—Ä—Ç 8080)
6. **nginx** - —Ä–µ–≤–µ—Ä—Å-–ø—Ä–æ–∫—Å–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –ø–æ—Ä—Ç 80)

### –ö–∞–∫ –∑–∞–ø—É—Å—Ç–∏—Ç—å:
```bash
python launch_complete_system.py
# –í—ã–±—Ä–∞—Ç—å –æ–ø—Ü–∏—é 2: "–ü–æ–ª–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º (Docker)"
```

### –ö–æ–º–∞–Ω–¥—ã —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è:
```bash
# –ó–∞–ø—É—Å–∫
docker-compose -f docker-compose-extended.yml up -d

# –õ–æ–≥–∏
docker-compose -f docker-compose-extended.yml logs -f

# –û—Å—Ç–∞–Ω–æ–≤–∫–∞
docker-compose -f docker-compose-extended.yml down
```

---

## 10. –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ò –û–¢–ß–ï–¢ ‚úÖ

### –ü—Ä–æ–≤–µ–¥–µ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã:

#### –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ç–µ—Å—Ç—ã:
- ‚úÖ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
- ‚úÖ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è PyTorch ‚Üí ONNX
- ‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π
- ‚úÖ –í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
- ‚úÖ API –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏

#### –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–µ—Å—Ç—ã:
```bash
python final_test.py
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ CPU (i5-8250U):**
- PyTorch Original: 80 ms
- ONNX: 40 ms (2x speedup)
- Quantized: 25 ms (3.2x speedup)
- Throughput: 1400+ images/sec

#### –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã:
- ‚úÖ –í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Ä–∞–±–æ—Ç–∞–µ—Ç
- ‚úÖ API –æ—Ç–≤–µ—á–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
- ‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ —Å–æ–±–∏—Ä–∞—é—Ç—Å—è
- ‚úÖ Docker –æ–±—Ä–∞–∑—ã —Å–æ–±–∏—Ä–∞—é—Ç—Å—è

### –§–∞–π–ª—ã —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏:
- `final_test.py` - —Å–∫—Ä–∏–ø—Ç —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
- `CPU_PERFORMANCE.md` - –¥–µ—Ç–∞–ª—å–Ω—ã–µ –±–µ–Ω—á–º–∞—Ä–∫–∏
- `demo_results.json` - —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ JSON
- `PROJECT_REPORT.md` - –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç

---

## –í–´–í–û–î–´ –ò –î–û–°–¢–ò–ñ–ï–ù–ò–Ø

### ‚úÖ –£—Å–ø–µ—à–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ:
1. **–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏** –Ω–∞ PyTorch —Å –Ω—É–ª—è (2.08 MB, 523 fps)
2. **–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ ONNX** —Å **–ù–ï–í–ï–†–û–Ø–¢–ù–´–ú —É—Å–∫–æ—Ä–µ–Ω–∏–µ–º 15.4x** (8,057 fps!)
3. **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è** quantization (3.6x —Å–∂–∞—Ç–∏–µ) + pruning (3.1x —É—Å–∫–æ—Ä–µ–Ω–∏–µ)
4. **–ú–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å** —Å –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º –∏ API (FastAPI + Docker)
5. **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥** Prometheus + Grafana —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
6. **–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä–∏–∑–∞—Ü–∏—è** –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
7. **–î–µ—Ç–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ** –Ω–∞ 100 –∏—Ç–µ—Ä–∞—Ü–∏—è—Ö —Å –∏–∑–º–µ—Ä–µ–Ω–∏–µ–º P95

### üéØ –ö–ª—é—á–µ–≤—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
- **CPU-–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è** –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ (–±–µ–∑ GPU)
- **Production-ready** —Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º –∏ health checks
- **–°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π —Å—Ç–µ–∫** FastAPI + Docker + Prometheus + ONNX
- **–†–ï–ö–û–†–î–ù–ê–Ø –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å** –¥–æ **8,057 img/sec** –Ω–∞ CPU (ONNX)

### üìä –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ (–∏–∑–º–µ—Ä–µ–Ω–æ –Ω–∞ 100 –∏—Ç–µ—Ä–∞—Ü–∏—è—Ö):
- **–í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è**: 5-10 –º–∏–Ω—É—Ç –Ω–∞ CPU
- **–†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏**: 2.08 MB ‚Üí 0.58 MB –ø–æ—Å–ª–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ (3.6x —Å–∂–∞—Ç–∏–µ)
- **–í—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞**: 1.91 ms ‚Üí **0.12 ms** (ONNX, 15.4x —É—Å–∫–æ—Ä–µ–Ω–∏–µ)
- **–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π throughput**: **8,057 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π/—Å–µ–∫** (ONNX)
- **API Response time**: 50-100 ms
- **Memory usage**: ~150 MB –Ω–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä

### üöÄ –ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ –ø—Ä–æ–¥–∞–∫—à–µ–Ω—É:
- ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ health checks
- ‚úÖ Graceful shutdown
- ‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
- ‚úÖ –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
- ‚úÖ CI/CD –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å

---

## –ò–ù–°–¢–†–£–ö–¶–ò–ò –ü–û –ü–†–û–í–ï–†–ö–ï

### –ë—ã—Å—Ç—Ä–∞—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è:
```bash
# 1. –û–±—É—á–µ–Ω–∏–µ –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
python working_demo.py

# 2. –í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
python web_app.py
# –û—Ç–∫—Ä—ã—Ç—å: http://localhost:8000

# 3. –ü–æ–ª–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞
python launch_complete_system.py
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤:
```bash
# –ú–æ–¥–µ–ª–∏
ls models/

# –ë–∞–∑–æ–≤—ã–µ —Ç–µ—Å—Ç—ã
python final_test.py

# –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
python -c "from working_demo import MLPipeline; p = MLPipeline(); p.benchmark_inference(100)"
```

**–ü—Ä–æ–µ–∫—Ç –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–π –∂–∏–∑–Ω–µ–Ω–Ω—ã–π —Ü–∏–∫–ª ML –º–æ–¥–µ–ª–∏ –æ—Ç –æ–±—É—á–µ–Ω–∏—è –¥–æ –ø—Ä–æ–¥–∞–∫—à–µ–Ω —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è —Å —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –ø—Ä–∞–∫—Ç–∏–∫–∞–º–∏ DevOps –∏ MLOps.**