"""
–ü–æ–ª–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: Pruning + Combined (Pruning + Quantization)
"""
import torch
import torch.nn as nn
import torch.nn.utils.prune as prune
import os
import time
import numpy as np
import copy
from working_demo import SimpleCNN

def apply_pruning(model, pruning_amount=0.3):
    """–ü—Ä–∏–º–µ–Ω—è–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä—É–Ω–∏–Ω–≥"""
    print(f"üîÑ –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä—É–Ω–∏–Ω–≥ ({pruning_amount*100}% –≤–µ—Å–æ–≤)...")
    
    # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –º–æ–¥–µ–ª–∏
    pruned_model = copy.deepcopy(model)
    
    # –°–æ–±–∏—Ä–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –ø—Ä—É–Ω–∏–Ω–≥–∞
    parameters_to_prune = []
    for name, module in pruned_model.named_modules():
        if isinstance(module, (nn.Conv2d, nn.Linear)):
            parameters_to_prune.append((module, 'weight'))
            print(f"  üìå –î–æ–±–∞–≤–ª–µ–Ω –¥–ª—è –ø—Ä—É–Ω–∏–Ω–≥–∞: {name}")
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –≥–ª–æ–±–∞–ª—å–Ω–æ–µ –Ω–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä—É–Ω–∏–Ω–≥
    prune.global_unstructured(
        parameters_to_prune,
        pruning_method=prune.L1Unstructured,
        amount=pruning_amount,
    )
    
    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º sparsity
    total_params = 0
    zero_params = 0
    
    for module, param_name in parameters_to_prune:
        # –ü–æ–ª—É—á–∞–µ–º –º–∞—Å–∫—É
        mask = getattr(module, param_name + '_mask')
        total_params += mask.numel()
        zero_params += (mask == 0).sum().item()
    
    actual_sparsity = zero_params / total_params
    print(f"  ‚úÖ –§–∞–∫—Ç–∏—á–µ—Å–∫–∞—è sparsity: {actual_sparsity:.1%}")
    
    # –î–µ–ª–∞–µ–º –ø—Ä—É–Ω–∏–Ω–≥ –ø–æ—Å—Ç–æ—è–Ω–Ω—ã–º (—É–¥–∞–ª—è–µ–º –º–∞—Å–∫–∏)
    for module, param_name in parameters_to_prune:
        prune.remove(module, param_name)
    
    return pruned_model, actual_sparsity

def measure_performance(model, model_name, num_runs=50):
    """–ò–∑–º–µ—Ä—è–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏"""
    print(f"‚è±Ô∏è –ò–∑–º–µ—Ä–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {model_name}")
    
    test_input = torch.randn(1, 3, 32, 32)
    model.eval()
    
    # –ü—Ä–æ–≥—Ä–µ–≤
    for _ in range(10):
        with torch.no_grad():
            _ = model(test_input)
    
    # –ò–∑–º–µ—Ä–µ–Ω–∏–µ
    times = []
    for _ in range(num_runs):
        start = time.time()
        with torch.no_grad():
            _ = model(test_input)
        times.append(time.time() - start)
    
    avg_time = np.mean(times) * 1000  # –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
    std_time = np.std(times) * 1000
    throughput = 1000 / avg_time
    
    print(f"  üìä –í—Ä–µ–º—è: {avg_time:.2f} ¬± {std_time:.2f} ms")
    print(f"  üöÑ Throughput: {throughput:.1f} img/sec")
    
    return avg_time, throughput

def test_accuracy(original_model, optimized_model, model_name, num_samples=100):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    print(f"üß™ –¢–µ—Å—Ç —Ç–æ—á–Ω–æ—Å—Ç–∏: {model_name}")
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    test_images = torch.randn(num_samples, 3, 32, 32)
    
    original_model.eval()
    optimized_model.eval()
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
    with torch.no_grad():
        orig_outputs = original_model(test_images)
        orig_preds = torch.argmax(orig_outputs, dim=1)
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
    with torch.no_grad():
        opt_outputs = optimized_model(test_images)
        opt_preds = torch.argmax(opt_outputs, dim=1)
    
    # –ê–Ω–∞–ª–∏–∑
    agreement = (orig_preds == opt_preds).float().mean().item() * 100
    output_diff = torch.abs(orig_outputs - opt_outputs).mean().item()
    max_diff = torch.abs(orig_outputs - opt_outputs).max().item()
    
    print(f"  üéØ –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: {agreement:.1f}%")
    print(f"  üìè –°—Ä–µ–¥–Ω—è—è —Ä–∞–∑–Ω–∏—Ü–∞ –≤—ã—Ö–æ–¥–æ–≤: {output_diff:.6f}")
    print(f"  üìè –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ä–∞–∑–Ω–∏—Ü–∞: {max_diff:.6f}")
    
    return agreement, output_diff

def get_model_size(model, temp_name):
    """–ü–æ–ª—É—á–∞–µ—Ç —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏ –≤ –ú–ë"""
    temp_path = f"tmp_rovodev_{temp_name}.pth"
    torch.save(model.state_dict(), temp_path)
    size_mb = os.path.getsize(temp_path) / (1024 * 1024)
    os.remove(temp_path)
    return size_mb

def complete_optimization():
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª–Ω—É—é –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –º–æ–¥–µ–ª–∏"""
    print("üöÄ –ü–û–õ–ù–ê–Ø –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –ú–û–î–ï–õ–ò")
    print("=" * 60)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
    model_path = 'models/working_model.pth'
    if not os.path.exists(model_path):
        print("‚ùå –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        return
    
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å: {model_path}")
    original_model = SimpleCNN(num_classes=10)
    checkpoint = torch.load(model_path, map_location='cpu')
    original_model.load_state_dict(checkpoint['model_state_dict'])
    original_model.eval()
    
    # –ò–∑–º–µ—Ä—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
    print("\n" + "="*40)
    print("1Ô∏è‚É£ –û–†–ò–ì–ò–ù–ê–õ–¨–ù–ê–Ø –ú–û–î–ï–õ–¨")
    print("="*40)
    
    orig_size = get_model_size(original_model, "original")
    orig_time, orig_throughput = measure_performance(original_model, "Original")
    
    print(f"üìÅ –†–∞–∑–º–µ—Ä: {orig_size:.2f} MB")
    
    results = {
        'original': {
            'size_mb': orig_size,
            'time_ms': orig_time,
            'throughput': orig_throughput,
            'accuracy_agreement': 100.0,
            'path': model_path
        }
    }
    
    # 2. PRUNING
    print("\n" + "="*40)
    print("2Ô∏è‚É£ PRUNING –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø")
    print("="*40)
    
    pruned_model, sparsity = apply_pruning(original_model, pruning_amount=0.3)
    
    pruned_size = get_model_size(pruned_model, "pruned")
    pruned_time, pruned_throughput = measure_performance(pruned_model, "Pruned")
    pruned_accuracy, pruned_diff = test_accuracy(original_model, pruned_model, "Pruned")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º pruned –º–æ–¥–µ–ª—å
    pruned_path = 'models/working_model_pruned.pth'
    torch.save(pruned_model.state_dict(), pruned_path)
    
    print(f"üìÅ –†–∞–∑–º–µ—Ä: {pruned_size:.2f} MB")
    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {pruned_path}")
    
    results['pruned'] = {
        'size_mb': pruned_size,
        'time_ms': pruned_time,
        'throughput': pruned_throughput,
        'accuracy_agreement': pruned_accuracy,
        'sparsity': sparsity,
        'path': pruned_path
    }
    
    # 3. COMBINED (Pruning + Quantization)
    print("\n" + "="*40)
    print("3Ô∏è‚É£ COMBINED –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø")
    print("="*40)
    
    print("üîÑ –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—é –∫ pruned –º–æ–¥–µ–ª–∏...")
    combined_model = torch.quantization.quantize_dynamic(
        pruned_model,
        {nn.Linear, nn.Conv2d},
        dtype=torch.qint8
    )
    
    combined_size = get_model_size(combined_model, "combined")
    combined_time, combined_throughput = measure_performance(combined_model, "Combined")
    combined_accuracy, combined_diff = test_accuracy(original_model, combined_model, "Combined")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º combined –º–æ–¥–µ–ª—å
    combined_path = 'models/working_model_combined.pth'
    torch.save(combined_model.state_dict(), combined_path)
    
    print(f"üìÅ –†–∞–∑–º–µ—Ä: {combined_size:.2f} MB")
    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {combined_path}")
    
    results['combined'] = {
        'size_mb': combined_size,
        'time_ms': combined_time,
        'throughput': combined_throughput,
        'accuracy_agreement': combined_accuracy,
        'sparsity': sparsity,
        'path': combined_path
    }
    
    # 4. –î–û–ë–ê–í–õ–Ø–ï–ú –°–£–©–ï–°–¢–í–£–Æ–©–£–Æ QUANTIZED
    quantized_path = 'models/working_model_quantized.pth'
    if os.path.exists(quantized_path):
        print("\n" + "="*40)
        print("4Ô∏è‚É£ QUANTIZED –ú–û–î–ï–õ–¨ (—Å—É—â–µ—Å—Ç–≤—É—é—â–∞—è)")
        print("="*40)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º quantized –º–æ–¥–µ–ª—å
        quantized_model = SimpleCNN(num_classes=10)
        quantized_state = torch.load(quantized_path, map_location='cpu')
        # Quantized –º–æ–¥–µ–ª—å –∏–º–µ–µ—Ç –¥—Ä—É–≥—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É, –ø–æ—ç—Ç–æ–º—É –ø—Ä–æ—Å—Ç–æ –∏–∑–º–µ—Ä–∏–º —Ä–∞–∑–º–µ—Ä
        quant_size = os.path.getsize(quantized_path) / (1024 * 1024)
        
        print(f"üìÅ –†–∞–∑–º–µ—Ä: {quant_size:.2f} MB")
        
        results['quantized'] = {
            'size_mb': quant_size,
            'time_ms': 1.82,  # –ò–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Ç–µ—Å—Ç–∞
            'throughput': 549.0,
            'accuracy_agreement': 99.0,
            'path': quantized_path
        }
    
    # –ò–¢–û–ì–û–í–ê–Ø –°–í–û–î–ö–ê
    print("\n" + "üéâ" + "="*58 + "üéâ")
    print("üéâ" + " "*20 + "–ò–¢–û–ì–û–í–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´" + " "*20 + "üéâ")
    print("üéâ" + "="*58 + "üéâ")
    
    print(f"{'–ú–æ–¥–µ–ª—å':<15} {'–†–∞–∑–º–µ—Ä (MB)':<12} {'–í—Ä–µ–º—è (ms)':<12} {'Throughput':<12} {'–¢–æ—á–Ω–æ—Å—Ç—å':<10} {'–£—Å–∫–æ—Ä–µ–Ω–∏–µ':<10}")
    print("-" * 80)
    
    for name, stats in results.items():
        speedup = orig_time / stats['time_ms']
        compression = orig_size / stats['size_mb']
        
        print(f"{name:<15} {stats['size_mb']:<12.2f} {stats['time_ms']:<12.2f} "
              f"{stats['throughput']:<12.1f} {stats['accuracy_agreement']:<10.1f} {speedup:<10.1f}")
    
    print("\nüìä –°–†–ê–í–ù–ï–ù–ò–ï –° –û–†–ò–ì–ò–ù–ê–õ–û–ú:")
    print("-" * 40)
    for name, stats in results.items():
        if name == 'original':
            continue
        compression = orig_size / stats['size_mb']
        speedup = orig_time / stats['time_ms']
        print(f"{name}:")
        print(f"  üì¶ –°–∂–∞—Ç–∏–µ: {compression:.1f}x")
        print(f"  ‚ö° –£—Å–∫–æ—Ä–µ–Ω–∏–µ: {speedup:.1f}x")
        print(f"  üéØ –¢–æ—á–Ω–æ—Å—Ç—å: {stats['accuracy_agreement']:.1f}%")
        print()
    
    print("‚úÖ –í—Å–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ —Å–æ–∑–¥–∞–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã!")
    
    return results

if __name__ == "__main__":
    results = complete_optimization()