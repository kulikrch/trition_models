"""
–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –≤—Å–µ—Ö –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
"""
import torch
import torch.nn as nn
import onnxruntime as ort
import os
import time
import numpy as np
import json
from working_demo import SimpleCNN

class ModelBenchmark:
    def __init__(self):
        self.device = 'cpu'
        self.test_runs = 100  # –ë–æ–ª—å—à–µ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
        self.warmup_runs = 20
        
        # CIFAR-10 –∫–ª–∞—Å—Å—ã –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
        self.class_names = [
            'airplane', 'automobile', 'bird', 'cat', 'deer',
            'dog', 'frog', 'horse', 'ship', 'truck'
        ]
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
        self.mean = np.array([0.4914, 0.4822, 0.4465])
        self.std = np.array([0.2023, 0.1994, 0.2010])
        
    def create_test_data(self, batch_size=1):
        """–°–æ–∑–¥–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ"""
        return torch.randn(batch_size, 3, 32, 32)
    
    def benchmark_pytorch_model(self, model_path, model_name):
        """–ë–µ–Ω—á–º–∞—Ä–∫ PyTorch –º–æ–¥–µ–ª–∏"""
        print(f"üîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ {model_name}...")
        
        if not os.path.exists(model_path):
            print(f"‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {model_path}")
            return None
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        model = SimpleCNN(num_classes=10)
        
        if 'quantized' in model_path or 'combined' in model_path:
            # –î–ª—è –∫–≤–∞–Ω—Ç–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –Ω—É–∂–µ–Ω –æ—Å–æ–±—ã–π –ø–æ–¥—Ö–æ–¥
            try:
                state_dict = torch.load(model_path, map_location='cpu')
                model.load_state_dict(state_dict)
            except:
                # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∞–ø—Ä—è–º—É—é, –ø–µ—Ä–µ—Å–æ–∑–¥–∞–µ–º –∫–≤–∞–Ω—Ç–∏–∑–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å
                original_model = SimpleCNN(num_classes=10)
                original_checkpoint = torch.load('models/working_model.pth', map_location='cpu')
                original_model.load_state_dict(original_checkpoint['model_state_dict'])
                
                if 'quantized' in model_path:
                    model = torch.quantization.quantize_dynamic(
                        original_model, {nn.Linear, nn.Conv2d}, dtype=torch.qint8
                    )
                elif 'combined' in model_path:
                    # –ó–¥–µ—Å—å –Ω—É–∂–Ω–æ –±—ã–ª–æ –±—ã –ø—Ä–∏–º–µ–Ω–∏—Ç—å –ø—Ä—É–Ω–∏–Ω–≥, –Ω–æ –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—é
                    model = torch.quantization.quantize_dynamic(
                        original_model, {nn.Linear, nn.Conv2d}, dtype=torch.qint8
                    )
        else:
            # –û–±—ã—á–Ω–∞—è –º–æ–¥–µ–ª—å
            checkpoint = torch.load(model_path, map_location='cpu')
            if 'model_state_dict' in checkpoint:
                model.load_state_dict(checkpoint['model_state_dict'])
            else:
                model.load_state_dict(checkpoint)
        
        model.eval()
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        test_input = self.create_test_data()
        
        # –ü—Ä–æ–≥—Ä–µ–≤
        for _ in range(self.warmup_runs):
            with torch.no_grad():
                _ = model(test_input)
        
        # –ë–µ–Ω—á–º–∞—Ä–∫
        times = []
        for _ in range(self.test_runs):
            start_time = time.perf_counter()
            with torch.no_grad():
                output = model(test_input)
            end_time = time.perf_counter()
            times.append(end_time - start_time)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        avg_time = np.mean(times) * 1000  # ms
        std_time = np.std(times) * 1000
        min_time = np.min(times) * 1000
        max_time = np.max(times) * 1000
        p95_time = np.percentile(times, 95) * 1000
        
        # –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
        file_size = os.path.getsize(model_path) / (1024 * 1024)  # MB
        
        # –¢–µ—Å—Ç–æ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        with torch.no_grad():
            test_output = model(test_input)
            predicted_class = torch.argmax(test_output, dim=1).item()
            confidence = torch.softmax(test_output, dim=1).max().item()
        
        results = {
            'model_name': model_name,
            'file_path': model_path,
            'file_size_mb': file_size,
            'avg_time_ms': avg_time,
            'std_time_ms': std_time,
            'min_time_ms': min_time,
            'max_time_ms': max_time,
            'p95_time_ms': p95_time,
            'throughput_fps': 1000 / avg_time,
            'predicted_class': self.class_names[predicted_class],
            'confidence': confidence,
            'test_runs': self.test_runs
        }
        
        print(f"  üìä –í—Ä–µ–º—è: {avg_time:.2f} ¬± {std_time:.2f} ms")
        print(f"  üöÑ Throughput: {1000/avg_time:.1f} img/sec")
        print(f"  üìÅ –†–∞–∑–º–µ—Ä: {file_size:.2f} MB")
        print(f"  üéØ –¢–µ—Å—Ç: {self.class_names[predicted_class]} ({confidence:.3f})")
        
        return results
    
    def benchmark_onnx_model(self, onnx_path, model_name="ONNX"):
        """–ë–µ–Ω—á–º–∞—Ä–∫ ONNX –º–æ–¥–µ–ª–∏"""
        print(f"üîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ {model_name}...")
        
        if not os.path.exists(onnx_path):
            print(f"‚ùå ONNX –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {onnx_path}")
            return None
        
        # –°–æ–∑–¥–∞–µ–º ONNX Runtime —Å–µ—Å—Å–∏—é
        try:
            ort_session = ort.InferenceSession(onnx_path)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ ONNX: {e}")
            return None
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        test_input = self.create_test_data().numpy().astype(np.float32)
        
        # –ü—Ä–æ–≥—Ä–µ–≤
        for _ in range(self.warmup_runs):
            ort_inputs = {ort_session.get_inputs()[0].name: test_input}
            _ = ort_session.run(None, ort_inputs)
        
        # –ë–µ–Ω—á–º–∞—Ä–∫
        times = []
        for _ in range(self.test_runs):
            start_time = time.perf_counter()
            ort_inputs = {ort_session.get_inputs()[0].name: test_input}
            output = ort_session.run(None, ort_inputs)
            end_time = time.perf_counter()
            times.append(end_time - start_time)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        avg_time = np.mean(times) * 1000  # ms
        std_time = np.std(times) * 1000
        min_time = np.min(times) * 1000
        max_time = np.max(times) * 1000
        p95_time = np.percentile(times, 95) * 1000
        
        # –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
        file_size = os.path.getsize(onnx_path) / (1024 * 1024)  # MB
        
        # –¢–µ—Å—Ç–æ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        ort_inputs = {ort_session.get_inputs()[0].name: test_input}
        onnx_output = ort_session.run(None, ort_inputs)[0]
        predicted_class = np.argmax(onnx_output, axis=1)[0]
        confidence = np.max(onnx_output)
        
        results = {
            'model_name': model_name,
            'file_path': onnx_path,
            'file_size_mb': file_size,
            'avg_time_ms': avg_time,
            'std_time_ms': std_time,
            'min_time_ms': min_time,
            'max_time_ms': max_time,
            'p95_time_ms': p95_time,
            'throughput_fps': 1000 / avg_time,
            'predicted_class': self.class_names[predicted_class],
            'confidence': float(confidence),
            'test_runs': self.test_runs
        }
        
        print(f"  üìä –í—Ä–µ–º—è: {avg_time:.2f} ¬± {std_time:.2f} ms")
        print(f"  üöÑ Throughput: {1000/avg_time:.1f} img/sec")
        print(f"  üìÅ –†–∞–∑–º–µ—Ä: {file_size:.2f} MB")
        print(f"  üéØ –¢–µ—Å—Ç: {self.class_names[predicted_class]} ({confidence:.3f})")
        
        return results
    
    def run_comprehensive_benchmark(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π"""
        print("üöÄ –ö–û–ú–ü–õ–ï–ö–°–ù–´–ô –ë–ï–ù–ß–ú–ê–†–ö –í–°–ï–• –ú–û–î–ï–õ–ï–ô")
        print("=" * 70)
        print(f"üìä –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:")
        print(f"   ‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–≥–æ–Ω–æ–≤: {self.test_runs}")
        print(f"   ‚Ä¢ –ü—Ä–æ–≥—Ä–µ–≤: {self.warmup_runs} –∏—Ç–µ—Ä–∞—Ü–∏–π")
        print(f"   ‚Ä¢ –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")
        print(f"   ‚Ä¢ –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: 1")
        print()
        
        results = []
        
        # –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        models_to_test = [
            ('models/working_model.pth', 'PyTorch Original'),
            ('models/working_model.onnx', 'ONNX'),
            ('models/working_model_quantized.pth', 'PyTorch Quantized'),
            ('models/working_model_pruned.pth', 'PyTorch Pruned'),
            ('models/working_model_combined.pth', 'PyTorch Combined'),
        ]
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é –º–æ–¥–µ–ª—å
        for i, (model_path, model_name) in enumerate(models_to_test, 1):
            print(f"\n{i}Ô∏è‚É£ {'='*50}")
            print(f"{i}Ô∏è‚É£ {model_name.upper()}")
            print(f"{i}Ô∏è‚É£ {'='*50}")
            
            if model_path.endswith('.onnx'):
                result = self.benchmark_onnx_model(model_path, model_name)
            else:
                result = self.benchmark_pytorch_model(model_path, model_name)
            
            if result:
                results.append(result)
        
        # –ò—Ç–æ–≥–æ–≤–∞—è —Å–≤–æ–¥–∫–∞
        if results:
            self.print_summary_table(results)
            self.save_results(results)
        
        return results
    
    def print_summary_table(self, results):
        """–ü–µ—á–∞—Ç–∞–µ—Ç –∏—Ç–æ–≥–æ–≤—É—é —Ç–∞–±–ª–∏—Ü—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        print("\n" + "üéâ" + "="*80 + "üéâ")
        print("üéâ" + " "*30 + "–ò–¢–û–ì–û–í–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´" + " "*30 + "üéâ")
        print("üéâ" + "="*80 + "üéâ")
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Ç–∞–±–ª–∏—Ü—ã
        print(f"{'–ú–æ–¥–µ–ª—å':<20} {'–†–∞–∑–º–µ—Ä':<10} {'–í—Ä–µ–º—è (ms)':<12} {'Throughput':<12} {'P95 (ms)':<10}")
        print("-" * 80)
        
        # –ù–∞—Ö–æ–¥–∏–º baseline (–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å)
        baseline = None
        for result in results:
            if 'original' in result['model_name'].lower():
                baseline = result
                break
        
        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        for result in results:
            name = result['model_name']
            size = f"{result['file_size_mb']:.2f} MB"
            time_ms = f"{result['avg_time_ms']:.2f}"
            throughput = f"{result['throughput_fps']:.1f} fps"
            p95 = f"{result['p95_time_ms']:.2f}"
            
            print(f"{name:<20} {size:<10} {time_ms:<12} {throughput:<12} {p95:<10}")
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å baseline
        if baseline:
            print(f"\nüìä –°–†–ê–í–ù–ï–ù–ò–ï –° BASELINE ({baseline['model_name']}):")
            print("-" * 60)
            
            for result in results:
                if result == baseline:
                    continue
                
                name = result['model_name']
                size_ratio = baseline['file_size_mb'] / result['file_size_mb']
                speed_ratio = baseline['avg_time_ms'] / result['avg_time_ms']
                
                print(f"{name}:")
                print(f"  üì¶ –°–∂–∞—Ç–∏–µ: {size_ratio:.1f}x")
                print(f"  ‚ö° –£—Å–∫–æ—Ä–µ–Ω–∏–µ: {speed_ratio:.1f}x")
                if size_ratio > 1:
                    print(f"  üíæ –≠–∫–æ–Ω–æ–º–∏—è –º–µ—Å—Ç–∞: {(1-1/size_ratio)*100:.1f}%")
                print()
        
        # –õ—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        print("üèÜ –õ–£–ß–®–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
        print("-" * 30)
        
        fastest = min(results, key=lambda x: x['avg_time_ms'])
        smallest = min(results, key=lambda x: x['file_size_mb'])
        highest_throughput = max(results, key=lambda x: x['throughput_fps'])
        
        print(f"üöÄ –°–∞–º–∞—è –±—ã—Å—Ç—Ä–∞—è: {fastest['model_name']} ({fastest['avg_time_ms']:.2f} ms)")
        print(f"üì¶ –°–∞–º–∞—è –∫–æ–º–ø–∞–∫—Ç–Ω–∞—è: {smallest['model_name']} ({smallest['file_size_mb']:.2f} MB)")
        print(f"üöÑ –ù–∞–∏–≤—ã—Å—à–∏–π throughput: {highest_throughput['model_name']} ({highest_throughput['throughput_fps']:.1f} fps)")
    
    def save_results(self, results):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ JSON"""
        output_file = 'benchmark_results.json'
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        benchmark_data = {
            'metadata': {
                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
                'test_runs': self.test_runs,
                'warmup_runs': self.warmup_runs,
                'device': self.device,
                'platform': 'CPU'
            },
            'results': results
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(benchmark_data, f, indent=2, ensure_ascii=False)
        
        print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_file}")

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    benchmark = ModelBenchmark()
    results = benchmark.run_comprehensive_benchmark()
    
    if results:
        print(f"\n‚úÖ –ë–µ–Ω—á–º–∞—Ä–∫ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
        print(f"üìä –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(results)}")
        print(f"üéØ –ì–æ—Ç–æ–≤—ã –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ç—á–µ—Ç–∞!")
    else:
        print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –±–µ–Ω—á–º–∞—Ä–∫–∞")

if __name__ == "__main__":
    main()